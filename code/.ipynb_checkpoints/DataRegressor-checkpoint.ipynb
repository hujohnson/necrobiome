{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regression code\n",
    "===============\n",
    "\n",
    "This code takes the files output by the DataUnifier code and does regression on the data they contain, using various regression techniques.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import datetime\n",
    "timestamp = str(datetime.datetime.now()).replace(' ','_')\n",
    "import sys\n",
    "outfile=open(\"out.\"+timestamp,'w')\n",
    "\n",
    "\n",
    "print(\"Loading X and y data files\\n\\n\")\n",
    "import os\n",
    "path = \"../processed_data/\"\n",
    "files = os.listdir(path)\n",
    "Xfiles = [f for f in files if f[0]=='X' and f[-5:]=='JOINT']\n",
    "yfile = [f for f in files if f[0]=='y' and f[-5:]=='JOINT'][0]\n",
    "print (Xfiles,yfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print (\"Loading y data\")\n",
    "import numpy as np\n",
    "y = np.loadtxt(path+yfile)\n",
    "m = y.shape[0]\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print (\"Generating test/train split\")\n",
    "train_percentage = 0.80 #80% train, 20% test\n",
    "perm = np.random.permutation(m)\n",
    "train_indices = perm[:int(train_percentage*m)]\n",
    "test_indices = perm[int(train_percentage*m):]\n",
    "shuffle_all = np.random.permutation(m)\n",
    "\n",
    "#Historical values -- comment out to generate new values\n",
    "train_indices = np.array([61, 30, 0, 25, 39, 10, 38, 18, 23, 42, 19, 16, 14, 22, 32, 45, 3, 43, 60, 47, 52, 7, 20, 40, 53, 62, 24, 31, 9, 5, 49, 44, 15, 33, 17, 56, 13, 36, 57, 11, 1, 58, 35, 34, 6, 41, 50, 37, 54, 26, 29, 48, 65])\n",
    "test_indices = np.array([12, 8, 63, 59, 28, 21, 64, 66, 51, 46, 55, 4, 2, 27])\n",
    "shuffle_all = np.array([50, 25, 2, 41, 42, 37, 22, 54, 52, 61, 60, 38, 12, 53, 11, 63, 18, 4, 44, 33, 17, 26, 48, 1, 8, 30, 27, 51, 57, 5, 40, 3, 46, 45, 39, 7, 49, 55, 24, 65, 32, 43, 14, 21, 20, 64, 35, 16, 36, 58, 31, 0, 62, 10, 28, 34, 13, 47, 59, 56, 19, 15, 66, 29, 23, 6, 9])\n",
    "\n",
    "\n",
    "\n",
    "print (list(train_indices),list(test_indices))\n",
    "print (len(train_indices)+len(test_indices)==m)\n",
    "print (list(shuffle_all))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print (\"Generating training/testing values for y\")\n",
    "#both y and X are subject to the same random shuffle before training and testing indices are selected\n",
    "y = y[shuffle_all]\n",
    "\n",
    "#now select train/test split\n",
    "ytrain = y[train_indices]\n",
    "ytest = y[test_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code in this notebook will run all of the regressors selected below on all of the unified joint data.  \n",
    "To include a regressor you must make sure the lines\n",
    "\n",
    "    regressors.append(R)\n",
    "    grids.append(grid)\n",
    "\n",
    "which come below the declaration of the regressor are _not_ commented out.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, explained_variance_score\n",
    "from sklearn.ensemble.forest import RandomForestRegressor\n",
    "from sklearn.linear_model import Ridge,Lasso,LinearRegression,ElasticNet,BayesianRidge\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "regressors = []\n",
    "grids = []\n",
    "\n",
    "\"\"\"\n",
    "R = SVR()\n",
    "grid = {'C':np.logspace(-3,7,15),'gamma':np.logspace(-5, 5, 10)}\n",
    "regressors.append(R)\n",
    "grids.append(grid)\n",
    "\n",
    "R = BayesianRidge()\n",
    "grid = {'alpha_1':np.logspace(-8,0,5),'alpha_2':np.logspace(-8,0,5),'lambda_1':np.logspace(-8,0,5),'lambda_2':np.logspace(-8,0,5),'normalize':[True,False],'fit_intercept':[True,False]}\n",
    "regressors.append(R)\n",
    "grids.append(grid)\n",
    "\n",
    "R=RandomForestRegressor(random_state=1029138)\n",
    "grid={'max_leaf_nodes':[3,30,300,None],'max_depth':[3,30,300,None],'max_features':['sqrt'] }\n",
    "regressors.append(R)\n",
    "grids.append(grid)\n",
    "\n",
    "R = Ridge()\n",
    "grid={'alpha':np.hstack((np.linspace(.01,200,10),np.logspace(-5,7,15))),'normalize':[True,False],'fit_intercept':[True,False]}\n",
    "regressors.append(R)\n",
    "grids.append(grid)\n",
    "\n",
    "R = Lasso(max_iter=10000)\n",
    "grid={'alpha':np.hstack((np.linspace(.01,200,10),np.logspace(-5,7,15))),'normalize':[True,False],'fit_intercept':[True,False]}\n",
    "regressors.append(R)\n",
    "grids.append(grid)\n",
    "\n",
    "R = ElasticNet(max_iter=10000)\n",
    "grid={'l1_ratio':np.linspace(0,1,10),'alpha':np.hstack((np.linspace(.01,200,10),np.logspace(-5,7,15))),'normalize':[True,False],'fit_intercept':[True,False]}\n",
    "regressors.append(R)\n",
    "grids.append(grid)\n",
    "\"\"\"\n",
    "#Most regressors commented out.  Uncomment the above to include them.\n",
    "\n",
    "R = KNeighborsRegressor()\n",
    "grid={'n_neighbors':[1,2,3,4,5,10],'algorithm':['auto', 'ball_tree', 'kd_tree', 'brute'],'weights':['uniform','distance']}\n",
    "regressors.append(R)\n",
    "grids.append(grid)\n",
    "      \n",
    "\n",
    "\n",
    "models = zip(regressors,grids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def do_tests(name,yy,h,outfile=sys.stdout):\n",
    "    \"\"\"This code does statistical analysis for a hypothesis h and a corresponding vector of true values yy\"\"\"\n",
    "    print (name)\n",
    "    if outfile != sys.stdout:\n",
    "        print (name,file=outfile)\n",
    "    print(\"\\tMSE = %f\"%mean_squared_error(yy,h),file=outfile)\n",
    "    print(\"\\tRMSE = %f\"%np.sqrt(mean_squared_error(yy,h)),file=outfile)\n",
    "    print(\"\\tNRMSE = %f\"%(np.sqrt(mean_squared_error(yy,h))/y.mean()),file=outfile)\n",
    "    print(\"\\tMAE = %f\"%mean_absolute_error(yy,h),file=outfile)\n",
    "    print(\"\\tR squared = %f\"% r2_score(yy,h),file=outfile)\n",
    "    print(\"\\tvariance_explained = %f\"% explained_variance_score(yy,h),file=outfile)\n",
    "    print(\"\\n\"+\"-\"*5+\"\\n\",file=outfile)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"This code is currently configured to save the results in a timestamped file.  \n",
    "   Check the directory after you run the code to see the text file containing the output.\n",
    "   If you prefer for output to be done here, just add the line\n",
    "   outfile = sys.stdout\n",
    "   to the top of this cell.\"\"\"\n",
    "\n",
    "\n",
    "results = []\n",
    "\n",
    "for Xfile in Xfiles:\n",
    "    X = np.loadtxt(path+Xfile) #load data\n",
    "    print (X.shape,Xfile[2:],file=outfile) #output statement\n",
    "    print (X.shape,Xfile[2:]) #output statement\n",
    "    X = X[shuffle_all]\n",
    "    X = (X.transpose()/np.sum(X,axis=1)).transpose() #convert to percentages\n",
    "    Xtrain = X[train_indices] #train set\n",
    "    Xtest = X[test_indices] #test set\n",
    "\n",
    "    for regressor,grid in models:\n",
    "        regname= str(regressor)[:str(regressor).find(\"(\")]\n",
    "        print(regname,file=outfile)\n",
    "        print(regname)\n",
    "        dummy = DummyRegressor()\n",
    "        dummy.fit(Xtrain,ytrain)\n",
    "        h = dummy.predict(Xtest)\n",
    "        yy = ytest\n",
    "        do_tests(\"Dummy\",yy,h,outfile=outfile)\n",
    "        \n",
    "        clf = GridSearchCV(regressor, param_grid=[grid],cv=10,scoring='mean_absolute_error',n_jobs=4)\n",
    "        clf.fit(Xtrain, ytrain)\n",
    "        \n",
    "        h=clf.predict(Xtrain)\n",
    "        yy = ytrain\n",
    "        do_tests(\"Training\",yy,h,outfile=outfile)\n",
    "        print (\"crossval score = \",clf.best_score_,file=outfile)\n",
    "        \n",
    "        h=clf.predict(Xtest)\n",
    "        yy = ytest\n",
    "        do_tests(\"Validation\",yy,h,outfile=outfile)\n",
    "        print(\"\\t\\t\\t\\tBest model:\",clf.best_params_,file=outfile)\n",
    "        nrmse = np.sqrt(mean_squared_error(yy,h))/y.mean()\n",
    "        results.append((clf.best_score_,nrmse,regname,clf.best_params_,Xfile[2:],yy,h))\n",
    "outfile.close()        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "from scipy.stats.stats import pearsonr\n",
    "sr = sorted(map(list,results))\n",
    "xdat = [-r[0] for r in sr]\n",
    "ydat = [mean_absolute_error(r[-2],r[-1]) for r in sr]\n",
    "#results\n",
    "print (\"training error correlates with testing error with r=%0.2f and p = %f\\n\"%pearsonr(xdat,ydat))\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure()\n",
    "plt.title(\"Cross-validation vs validation\")\n",
    "plt.xlabel(\"cross-validation error\")\n",
    "#plt.ylim((0,6.5))\n",
    "plt.ylabel(\"validation error\")\n",
    "#plt.grid()\n",
    "plt.plot(xdat,ydat,'o', color=\"k\",label=\"models\")\n",
    "\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()\n",
    "\n",
    "#sorted by cross-val error on the training set\n",
    "\n",
    "print (\"Models sorted by validation error:\")\n",
    "for r in sorted(map(list,results),key=lambda b:mean_absolute_error(b[-2],b[-1])):\n",
    "    #print (list(r[:5]) ,mean_absolute_error(r[-2],r[-1]))\n",
    "    print (\"|%3.2f|%3.2f|%s|%3.2f|%s|\"%(-r[0],r[1],r[2],mean_absolute_error(r[-2],r[-1]),r[4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def dimensionality(r):\n",
    "    s = path+\"X_\"+r[4]\n",
    "    X = np.loadtxt(s)\n",
    "    return (X.shape[1])\n",
    "\n",
    "srr = sorted(results,key=dimensionality)\n",
    "xdat = [np.log(dimensionality(r)) for r in srr if r[2]==\"KNeighborsRegressor\"]\n",
    "ydat = [-r[0] for r in srr if r[2]==\"KNeighborsRegressor\"]\n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"KNeighborsRegressor dimensionality vs error\")\n",
    "plt.xlabel(\"Dimensionality of $X$ (logarithmic)\")\n",
    "#plt.ylim((0,6.5))\n",
    "plt.ylabel(\"Mean absolute error\")\n",
    "#plt.grid()\n",
    "plt.plot(xdat,ydat,'*', color=\"b\",label=\"cross-validation\",markersize=10)\n",
    "\n",
    "ydat = [mean_absolute_error(r[-2],r[-1]) for r in srr if r[2]==\"KNeighborsRegressor\"]\n",
    "\n",
    "plt.plot(xdat,ydat,'x', color=\"r\",label=\"validation\",markersize=10)\n",
    "\n",
    "\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print (\"Data sorted by dimensionality\")\n",
    "RTG = [(r[4],dimensionality(r),np.log(dimensionality(r))) for r in srr]\n",
    "for g in sorted(list(set(RTG)),key=lambda k:k[2]):\n",
    "    print (\"|%s|%d|%1.3f|\"%g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"This code is an alternative to the code in the above cell for running all regressors on all data \"\"\"\n",
    "\n",
    "results = []\n",
    "outfile = sys.stdout\n",
    "for Xfile in Xfiles:\n",
    "    X = np.loadtxt(path+Xfile) #load data\n",
    "    print (X.shape,Xfile[2:],file=outfile) #output statement\n",
    "    print (X.shape,Xfile[2:]) #output statement\n",
    "    X = X[shuffle_all]\n",
    "    X = (X.transpose()/np.sum(X,axis=1)).transpose() #convert to percentages\n",
    "    \n",
    "    for regressor,grid in models:\n",
    "        regname= str(regressor)[:str(regressor).find(\"(\")]\n",
    "        print(regname,file=outfile)\n",
    "        print(regname)\n",
    "        dgrid = {}\n",
    "        dummy = GridSearchCV(DummyRegressor(), param_grid=[dgrid],cv=10,scoring='mean_absolute_error',n_jobs=4)\n",
    "        D = dummy.fit(X,y)\n",
    "        print(\"Dummy \",D.best_score_,file=outfile)\n",
    "        \n",
    "        clf = GridSearchCV(regressor, param_grid=[grid],cv=10,scoring='mean_absolute_error',n_jobs=4)\n",
    "        A = clf.fit(X, y)\n",
    "        h = A.predict(X)\n",
    "        print(\"Actual \",A.best_score_,file=outfile)\n",
    "        \n",
    "        \n",
    "        \n",
    "        print(\"\\t\\t\\t\\tBest model:\",clf.best_params_,file=outfile)\n",
    "        \n",
    "        results.append((A.best_score_,regname,clf.best_params_,Xfile[2:],y,h))\n",
    "outfile.close()        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code in the following three cells displays the information in the \"results\" array which records the results of either of the two above cells.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#results sorted by explained_variance on validation set\n",
    "\n",
    "key = lambda r: -explained_variance_score(r[-2],r[-1])\n",
    "for r in sorted(results,key=key):\n",
    "    print (list(r[:2])+[r[4]] ,mean_absolute_error(r[-2],r[-1]),explained_variance_score(r[-2],r[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#sorted by cross-val error on the training set\n",
    "\n",
    "#print (results[0])\n",
    "for r in sorted(map(list,results)):\n",
    "    print (list(r[:3])+[r[4]] ,mean_absolute_error(r[-2],r[-1]))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code in the following few cells takes a close look at results on specific datasets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "#This saves the results in a timestamped file which begins with \"results\"\n",
    "\n",
    "results = np.array(results)\n",
    "np.save(\"results.\"+timestamp,results)\n",
    "np.save(\"train_indices.\"+timestamp,train_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#This loads previously saved results\n",
    "#(file name used is only an example -- your filename should be used instead.)\n",
    "results = np.load(\"results.2016-08-02_17:53:56.937693.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Here we redo a few of the above tests with the loaded data. \n",
    "\n",
    "sr = sorted(map(list,results))\n",
    "xdat = [-r[0] for r in sr]\n",
    "ydat = [mean_absolute_error(r[-2],r[-1]) for r in sr]\n",
    "#results\n",
    "print (pearsonr(xdat,ydat))\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure()\n",
    "plt.title(\"Cross-validation vs validation\")\n",
    "plt.xlabel(\"cross-validation error\")\n",
    "#plt.ylim((0,6.5))\n",
    "plt.ylabel(\"validation error\")\n",
    "#plt.grid()\n",
    "plt.plot(xdat,ydat,'o', color=\"k\",label=\"models\")\n",
    "\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()\n",
    "\n",
    "#sorted by cross-val error on the training set\n",
    "\n",
    "#print (results[0])\n",
    "for r in sorted(map(list,results),key=lambda b:mean_absolute_error(b[-2],b[-1])):\n",
    "    #print (list(r[:5]) ,mean_absolute_error(r[-2],r[-1]))\n",
    "    print (\"|%3.2f|%3.2f|%s|%3.2f|%s|\"%(-r[0],r[1],r[2],mean_absolute_error(r[-2],r[-1]),r[4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
